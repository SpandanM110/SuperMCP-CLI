# LLM Provider: ollama | openai | anthropic | groq | together | mistral | azure_openai
LLM_PROVIDER=ollama

# Local (Ollama)
LLM_ENDPOINT=http://localhost:11434/api/generate
LLM_MODEL={{llmConfig.model}}

# Cloud / BYOK - set your API key for your provider
# OPENAI_API_KEY=sk-...
# ANTHROPIC_API_KEY=sk-ant-...
# GROQ_API_KEY=gsk_...
# TOGETHER_API_KEY=...
# MISTRAL_API_KEY=...

# Azure OpenAI (set endpoint + key + deployment)
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
# AZURE_OPENAI_KEY=...
# AZURE_OPENAI_DEPLOYMENT=your-deployment

# Context
CONTEXT_PATH=./context/docs.json

# Logging
LOG_LEVEL=info
