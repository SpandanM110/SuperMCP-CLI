# LLM Configuration
LLM_ENDPOINT=http://localhost:11434/api/generate
LLM_MODEL={{llmConfig.model}}

# Context
CONTEXT_PATH=./context/docs.json

# Logging
LOG_LEVEL=info
